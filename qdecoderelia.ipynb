{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7421593,"sourceType":"datasetVersion","datasetId":4317656}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nimport pandas as pd\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport numpy as np\nimport zipfile\n\nimport math\n\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom os import listdir\nimport h5py as h5\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:08:51.525320Z","iopub.execute_input":"2024-01-18T23:08:51.525855Z","iopub.status.idle":"2024-01-18T23:08:56.187170Z","shell.execute_reply.started":"2024-01-18T23:08:51.525808Z","shell.execute_reply":"2024-01-18T23:08:56.186308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    import gwpy\n    from gwpy.timeseries import TimeSeries\nexcept ModuleNotFoundError:\n    !pip install --quiet gwpy\n    import gwpy\n    from gwpy.timeseries import TimeSeries","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:08:56.189114Z","iopub.execute_input":"2024-01-18T23:08:56.189972Z","iopub.status.idle":"2024-01-18T23:09:17.837023Z","shell.execute_reply.started":"2024-01-18T23:08:56.189933Z","shell.execute_reply":"2024-01-18T23:09:17.836105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:09:17.838207Z","iopub.execute_input":"2024-01-18T23:09:17.838679Z","iopub.status.idle":"2024-01-18T23:09:17.865741Z","shell.execute_reply.started":"2024-01-18T23:09:17.838645Z","shell.execute_reply":"2024-01-18T23:09:17.864782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:09:17.867482Z","iopub.execute_input":"2024-01-18T23:09:17.867771Z","iopub.status.idle":"2024-01-18T23:09:17.888282Z","shell.execute_reply.started":"2024-01-18T23:09:17.867747Z","shell.execute_reply":"2024-01-18T23:09:17.887365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"markdown","source":"**Load full dataset resampled to 500Hz and normalised** (according to def standardise(ts))","metadata":{}},{"cell_type":"code","source":"df=pd.read_pickle('/kaggle/input/img-pix2pix-gws-scattered-light/Image_dataset_1000')","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:09:29.792676Z","iopub.execute_input":"2024-01-18T23:09:29.793434Z","iopub.status.idle":"2024-01-18T23:09:57.634856Z","shell.execute_reply.started":"2024-01-18T23:09:29.793398Z","shell.execute_reply":"2024-01-18T23:09:57.633827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clean dataset by eliminating rows with Nan values","metadata":{}},{"cell_type":"code","source":"qplot_test=df.iloc[0,1]\nplt.figure(figsize=(12, 4))\nplt.imshow(qplot_test, aspect='auto', extent=[0, 16/3, 10, 150])\nplt.title('Downsampled Q-transform Spectrogram (Pillow)')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:09:57.636325Z","iopub.execute_input":"2024-01-18T23:09:57.636622Z","iopub.status.idle":"2024-01-18T23:09:58.383620Z","shell.execute_reply.started":"2024-01-18T23:09:57.636597Z","shell.execute_reply":"2024-01-18T23:09:58.382591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.applymap(lambda x: torch.tensor(x))","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:09:58.385009Z","iopub.execute_input":"2024-01-18T23:09:58.385374Z","iopub.status.idle":"2024-01-18T23:09:59.811976Z","shell.execute_reply.started":"2024-01-18T23:09:58.385343Z","shell.execute_reply":"2024-01-18T23:09:59.811139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split Data","metadata":{}},{"cell_type":"code","source":"df_aux_all_2d = pd.DataFrame(df[['V1:LSC_MICH_ERR', 'V1:LSC_NE_CORR','V1:LSC_PR_CORR']])#,'V1:LSC_DARM_ERR'\ndf_main_all_2d = pd.DataFrame(df['V1:Hrec_hoft_16384Hz'])","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:09:59.814137Z","iopub.execute_input":"2024-01-18T23:09:59.814523Z","iopub.status.idle":"2024-01-18T23:09:59.830059Z","shell.execute_reply.started":"2024-01-18T23:09:59.814491Z","shell.execute_reply":"2024-01-18T23:09:59.829125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(df_aux_all_2d, df_main_all_2d, test_size=0.1, random_state=42)\n\n#signal_data_train=torch.stack([torch.stack([df['V1:Hrec_hoft_16384Hz'][i]]) for i in range(n_train)])\n#aux_data_train=torch.stack([torch.stack([df_aux.loc[i][0],df_aux.loc[i][1],df_aux.loc[i][2],df_aux.loc[i][3],df_aux.loc[i][4]]) for i in range(n_train)])\nsignal_data_train_small_2d = torch.stack([torch.stack([y_train_2d['V1:Hrec_hoft_16384Hz'].iloc[i]]) for i in range(100)]) #for i in range(y_train.shape[0])\naux_data_train_small_2d = torch.stack([torch.stack([X_train_2d.iloc[i][0], X_train_2d.iloc[i][1], X_train_2d.iloc[i][2]]) for i in range(100)]) #for i in range(X_train.shape[0])\n\nsignal_data_train_2d = torch.stack([torch.stack([y_train_2d['V1:Hrec_hoft_16384Hz'].iloc[i]]) for i in range(y_train_2d.shape[0])]) #\naux_data_train_2d = torch.stack([torch.stack([X_train_2d.iloc[i][0], X_train_2d.iloc[i][1], X_train_2d.iloc[i][2]]) for i in range(X_train_2d.shape[0])]) #\n\n\n\ntrain_data_2d=torch.cat([signal_data_train_2d,aux_data_train_2d],dim=1) \ntrain_data_small_2d=torch.cat([signal_data_train_small_2d,aux_data_train_small_2d],dim=1) \n\nprint(signal_data_train_2d.shape)\nprint(aux_data_train_2d.shape)\n\n# Extract the signal and auxiliary data for testing\nsignal_data_test_small_2d = torch.stack([torch.stack([y_test_2d['V1:Hrec_hoft_16384Hz'].iloc[i]]) for i in range(100)]) #for i in range(y_test.shape[0])\naux_data_test_small_2d = torch.stack([torch.stack([X_test_2d.iloc[i][0], X_test_2d.iloc[i][1], X_test_2d.iloc[i][2]]) for i in range(100) ]) #for i in range(X_test.shape[0])\n\nsignal_data_test_2d = torch.stack([torch.stack([y_test_2d['V1:Hrec_hoft_16384Hz'].iloc[i]]) for i in range(y_test_2d.shape[0])]) #\naux_data_test_2d = torch.stack([torch.stack([X_test_2d.iloc[i][0], X_test_2d.iloc[i][1], X_test_2d.iloc[i][2]]) for i in range(X_test_2d.shape[0]) ]) #\n\ntest_data_2d = torch.cat([signal_data_test_2d, aux_data_test_2d], dim=1) \ntest_data_small_2d = torch.cat([signal_data_test_small_2d, aux_data_test_small_2d], dim=1) \n\nprint(signal_data_test_2d.shape)\nprint(aux_data_test_2d.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:15.175995Z","iopub.execute_input":"2024-01-18T23:10:15.176489Z","iopub.status.idle":"2024-01-18T23:10:18.348151Z","shell.execute_reply.started":"2024-01-18T23:10:15.176457Z","shell.execute_reply":"2024-01-18T23:10:18.347299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:21.108754Z","iopub.execute_input":"2024-01-18T23:10:21.109469Z","iopub.status.idle":"2024-01-18T23:10:21.113346Z","shell.execute_reply.started":"2024-01-18T23:10:21.109435Z","shell.execute_reply":"2024-01-18T23:10:21.112387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_(data,chan=4):\n    #data -= data.min((-1,-2), keepdim=True)[0]\n    data /=data.view(data.shape[0],chan,-1).max((-1), keepdim=True)[0].view(data.shape[0],chan,1,1)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:31.859908Z","iopub.execute_input":"2024-01-18T23:10:31.860739Z","iopub.status.idle":"2024-01-18T23:10:31.867026Z","shell.execute_reply.started":"2024-01-18T23:10:31.860696Z","shell.execute_reply":"2024-01-18T23:10:31.865736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_2d=normalize_(train_data_2d)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:35.830095Z","iopub.execute_input":"2024-01-18T23:10:35.831097Z","iopub.status.idle":"2024-01-18T23:10:36.447582Z","shell.execute_reply.started":"2024-01-18T23:10:35.831053Z","shell.execute_reply":"2024-01-18T23:10:36.446666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_2d=normalize_(test_data_2d)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:36.449384Z","iopub.execute_input":"2024-01-18T23:10:36.449768Z","iopub.status.idle":"2024-01-18T23:10:36.501443Z","shell.execute_reply.started":"2024-01-18T23:10:36.449734Z","shell.execute_reply":"2024-01-18T23:10:36.500539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test_data_2d[6,0])\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:39.808751Z","iopub.execute_input":"2024-01-18T23:10:39.809399Z","iopub.status.idle":"2024-01-18T23:10:40.265605Z","shell.execute_reply.started":"2024-01-18T23:10:39.809369Z","shell.execute_reply":"2024-01-18T23:10:40.264655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(train_data_2d[6,3])\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:40.267366Z","iopub.execute_input":"2024-01-18T23:10:40.267671Z","iopub.status.idle":"2024-01-18T23:10:40.770137Z","shell.execute_reply.started":"2024-01-18T23:10:40.267645Z","shell.execute_reply":"2024-01-18T23:10:40.769229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(\n    train_data_2d,\n    batch_size=batch_size,\n    shuffle=True,\n)\n\n\ntest_dataloader = DataLoader(\n    test_data_2d,\n    batch_size=batch_size,\n    shuffle=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:10:57.654240Z","iopub.execute_input":"2024-01-18T23:10:57.654645Z","iopub.status.idle":"2024-01-18T23:10:57.660168Z","shell.execute_reply.started":"2024-01-18T23:10:57.654614Z","shell.execute_reply":"2024-01-18T23:10:57.659126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"tags":[]}},{"cell_type":"code","source":"def init_weights(net, init_type='normal', scaling=0.02):\n    def init_func(m):  # define the initialization function\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and (classname.find('Conv')) != -1:\n            torch.nn.init.normal_(m.weight.data, 0.0, scaling)\n        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n            torch.nn.init.normal_(m.weight.data, 1.0, scaling)\n            torch.nn.init.constant_(m.bias.data, 0.0)\n\n    print('initialize network with %s' % init_type)\n    net.apply(init_func)  # apply the initialization function ","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:01.142433Z","iopub.execute_input":"2024-01-18T23:11:01.143279Z","iopub.status.idle":"2024-01-18T23:11:01.150194Z","shell.execute_reply.started":"2024-01-18T23:11:01.143232Z","shell.execute_reply":"2024-01-18T23:11:01.149132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generator","metadata":{"tags":[]}},{"cell_type":"markdown","source":"#### If you want to only use the Decoder, just run the next 3 cells and skip directly to the Training part","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[]}},{"cell_type":"code","source":"class RescaledSigmoid(nn.Module):\n    def __init__(self,a=80.0):\n        super().__init__()\n        self.scaling=torch.nn.Parameter(torch.tensor(a))\n        self.sigmoid = torch.nn.Sigmoid()\n        \n    def __call__(self,x):\n        return self.scaling *self.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:03.053230Z","iopub.execute_input":"2024-01-18T23:11:03.053594Z","iopub.status.idle":"2024-01-18T23:11:03.059507Z","shell.execute_reply.started":"2024-01-18T23:11:03.053568Z","shell.execute_reply":"2024-01-18T23:11:03.058399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, in_channels, kernel_size=7,a=80.0):\n        super(Decoder, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n        self.relu1 = nn.LeakyReLU(0.2, inplace=True)\n\n        self.conv2 = nn.Conv2d(32, 64,kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n        self.relu2 = nn.LeakyReLU(0.2, inplace=True)\n\n        self.conv3 = nn.Conv2d(64, 64,kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n        self.relu3 = nn.LeakyReLU(0.2, inplace=True)\n\n        self.conv4 = nn.Conv2d(64, 1, kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n        \n        \n        self.activation =torch.nn.Sigmoid()\n\n        self.scaled=RescaledSigmoid(a)\n    def _forward_features(self, x):\n        x = self.relu1(self.conv1(x))\n        x = self.relu2(self.conv2(x))\n        x = self.relu3(self.conv3(x))\n        x = self.conv4(x)\n        x= self.activation(x)\n        return x\n\n    def forward(self, x):\n        return self._forward_features(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:04.939161Z","iopub.execute_input":"2024-01-18T23:11:04.940046Z","iopub.status.idle":"2024-01-18T23:11:04.949777Z","shell.execute_reply.started":"2024-01-18T23:11:04.940010Z","shell.execute_reply":"2024-01-18T23:11:04.948594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_conv_net(hidden_sizes, kernel_size, in_channels, out_channels,bn,drop,activation='leaky'):\n    '''\n    Convolutionaal Neural Netowrk\n    hiddens_sizes=[N_filters for hidden layer 1, .... ,N_filters for hidden layer n]\n    num hidden layers = len(hidden_sizes)\n    kernel_size= kernel size for layer i (included output layer)\n    bn = add batch normalization after layer i if bn[i]==True\n    drop= add dropout with p=drop[i] if drop[i]!= None/False\n    dilation = dilation[i] dilation for layer i (included output)\n    activatio: choose one of leaky (leakyrelu), tanh, relu, gelu\n    '''\n    sizes = [in_channels] + hidden_sizes + [out_channels]\n    net = []\n    for i in range(len(sizes) - 1):\n        conv = torch.nn.Conv2d(sizes[i], sizes[i+1], kernel_size[i], padding=kernel_size[i]//2, stride=1, padding_mode='zeros',dilation=1)\n        net.append(conv)\n        if i != len(sizes) - 2:\n            if bn[i]:\n                net.append(nn.BatchNorm2d(sizes[i+1]))\n            if drop[i]:\n                net.append(nn.Dropout(p=drop[i]))\n            if activation==\"leaky\":\n                net.append(torch.nn.LeakyReLU(0.2))\n            elif activation==\"tanh\":\n                net.append(torch.nn.Tanh())\n            elif activation=='relu':\n                net.append(torch.nn.ReLU())\n            elif activation == 'gelu':\n                net.append(nn.GELU())\n            \n    return torch.nn.Sequential(*net)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:05.262773Z","iopub.execute_input":"2024-01-18T23:11:05.263144Z","iopub.status.idle":"2024-01-18T23:11:05.273078Z","shell.execute_reply.started":"2024-01-18T23:11:05.263115Z","shell.execute_reply":"2024-01-18T23:11:05.272154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResidualBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features)\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n\nclass GeneratorResNet(nn.Module):\n    def __init__(self, input_shape, num_residual_block, output_shape):\n        super(GeneratorResNet, self).__init__()\n\n        channels = input_shape\n        target_channels = output_shape\n        # Initial Convolution Block\n        out_features = 64\n        model = [\n            nn.ReflectionPad2d(channels),\n            nn.Conv2d(channels, out_features, 7),\n            nn.InstanceNorm2d(out_features),\n            nn.ReLU(inplace=True)\n        ]\n        in_features = out_features\n\n        # Downsampling\n        for _ in range(2):\n            out_features *= 2\n            model += [\n                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n\n        # Residual blocks\n        for _ in range(num_residual_block):\n            model += [ResidualBlock(out_features)]\n\n        # Upsampling\n        for _ in range(2):\n            out_features //= 2\n            model += [\n                nn.Upsample(scale_factor=2), # --> width*2, heigh*2\n                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n\n        # Output Layer\n        model += [nn.ReflectionPad2d(target_channels),\n                  nn.Conv2d(out_features,  target_channels, 3),\n                  nn.Sigmoid() #tune this activation\n                 ]\n\n        # Unpacking\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:05.697227Z","iopub.execute_input":"2024-01-18T23:11:05.697961Z","iopub.status.idle":"2024-01-18T23:11:05.710956Z","shell.execute_reply.started":"2024-01-18T23:11:05.697929Z","shell.execute_reply":"2024-01-18T23:11:05.709964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"tags":[]}},{"cell_type":"code","source":"# Metric function: IOU\n\ndef calculate_iou_2d(generated, target, threshold):\n    \"\"\"\n    Calculate Intersection over Union (IoU) in the 2D plane at the specified intensity threshold.\n\n    Parameters:\n    - generated: List of time series representing the generated spectrograms\n    - target: List of time series representing the target spectrograms\n    - threshold: Intensity threshold for determining the binary masks\n\n    Returns:\n    - IoU: Intersection over Union\n    \"\"\"\n    # Extract spectrogram values from time series\n    # print(generated[0][0])\n    # print(generated[0][0].shape)\n    # print(type(generated[0][0]))\n    \n    \n    spectrograms_gen = [TimeSeries(t[0], dt=1/4096.0).q_transform(frange=(10, 1000)).value for t in generated]\n    spectrograms_real = [TimeSeries(t[0], dt=1/4096.0).q_transform(frange=(10, 1000)).value for t in target]\n\n    # Create binary masks based on the intensity threshold\n    mask1 = [spectrogram >= threshold for spectrogram in spectrograms_gen]\n    mask2 = [spectrogram >= threshold for spectrogram in spectrograms_real]\n\n    # Calculate the intersection and union of the binary masks\n    intersection = [np.logical_and(m1, m2) for m1, m2 in zip(mask1, mask2)]\n    union = [np.logical_or(m1, m2) for m1, m2 in zip(mask1, mask2)]\n\n    # Calculate Intersection over Union (IoU)\n    iou_list = np.array([np.sum(inter) / np.sum(uni) for inter, uni in zip(intersection, union)])\n\n    iou = iou_list.mean()\n    return iou\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:06.618117Z","iopub.execute_input":"2024-01-18T23:11:06.618560Z","iopub.status.idle":"2024-01-18T23:11:06.628982Z","shell.execute_reply.started":"2024-01-18T23:11:06.618513Z","shell.execute_reply":"2024-01-18T23:11:06.627900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#more sophisticated loss function\n\ndef log_cosh_loss(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n    def _log_cosh(x: torch.Tensor) -> torch.Tensor:\n        return x + torch.nn.functional.softplus(-2. * x) - math.log(2.0)\n    return torch.mean(_log_cosh(y_pred - y_true))\n\nclass LogCoshLoss(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(\n        self, y_pred: torch.Tensor, y_true: torch.Tensor\n    ) -> torch.Tensor:\n        return log_cosh_loss(y_pred, y_true)\n\n# utils function to generate data using the decoder    \ndef generate_data(generator,batch):\n    #batch= transform(batch)\n    target = batch[:,0].unsqueeze(1).to(device)\n    input = batch[:,1:].to(device)\n    #print(input.float())\n    with torch.no_grad():\n        generated = generator(input.float())\n        generated=normalize_(generated,1)\n    return generated","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:07.194503Z","iopub.execute_input":"2024-01-18T23:11:07.195137Z","iopub.status.idle":"2024-01-18T23:11:07.203897Z","shell.execute_reply.started":"2024-01-18T23:11:07.195105Z","shell.execute_reply":"2024-01-18T23:11:07.202822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_decoder(num_epochs,generator,criterion,optimizer,dataloader,val_loader,accuracy,checkpoint_path, save_best=False):\n    # num_epochs: (int) number of epochs for training\n    # generator: (NN.Module) NN model to train\n    # criterion: (torch.optim) optimiser to use in training\n    # dataloader: (DataLoader) training data\n    # val_loader: (Dataloader) validation data\n    # accuracy: (function) metric to measure performance of the model (Note not to be confused with loss)\n    # checkpoint_path: (str) full path (including filename in the form filename_{}.pkl so to insert num_epoch) to save checkpoints at\n    # save_best: (bool) if you want to save best performing model\n    \n    \n    #uncomment all lines relative to accuracy if you want to measure IOU between generated and real spectrograms.\n    #Note that it significantly slows down the whole process\n    \n    loss_plot =[]\n    val_loss_plot =[]\n    acc_plot=[]\n    val_acc_plot=[]\n    best_val_loss=5000000\n    for epoch in tqdm(range(1,num_epochs+1)):\n        epoch_loss =[]\n        epoch_acc=[]\n        for i, batch in enumerate(dataloader):\n            #batch= transform(batch)\n            target = batch[:,0].unsqueeze(1).to(device)\n            target=target.float()\n            input = batch[:,1:].to(device)\n            \n            optimizer.zero_grad()\n            generated = generator(input.float())\n            #generated=normalize_(generated,1)\n            loss=criterion(generated,target)\n            loss.backward()\n            optimizer.step()\n            epoch_loss.append(loss.detach().cpu().numpy())\n            #acc=accuracy(generated.detach().cpu().numpy(),target.detach().cpu().numpy(),20)\n            #epoch_acc.append(acc)\n        val_loss =[]\n        val_acc=[]\n        for batch in(val_loader):\n            #batch= transform(batch)\n            target = batch[:,0].unsqueeze(1).to(device)\n            target=target.float()\n            input = batch[:,1:].to(device)\n            with torch.no_grad():\n                generated = generator(input.float())\n                #generated=normalize_(generated,1)\n                loss=criterion(generated,target)\n                val_loss.append(loss.detach().cpu().numpy())\n                #acc=accuracy(generated.detach().cpu().numpy(),target.detach().cpu().numpy(),20)\n                #val_acc.append(acc)\n        loss_plot.append(np.mean(epoch_loss))\n        val_loss_plot.append(np.mean(val_loss))\n        acc_plot.append(np.mean(epoch_acc))\n        val_acc_plot.append(np.mean(val_acc))\n        #print('epoch: {} loss: {} val loss: {} accuracy: {} val accuracy: {}'.format(epoch,loss_plot[-1],val_loss_plot[-1],acc_plot[-1],val_acc_plot[-1]))\n        print('epoch: {} loss: {} val loss: {}'.format(epoch,loss_plot[-1],val_loss_plot[-1]))\n        \n        # Save checkpoint every 100 epochs\n        if (epoch+1) % 100 == 0:\n            #uncomment the following if you want to save checkpoint every 100 epochs regardless of the performance of the model\n            # checkpoint = {\n            #     'epoch': epoch,\n            #     'model_state_dict': generator.state_dict(),\n            #     'optimizer_state_dict': optimizer.state_dict(),\n            #     'loss': loss_plot[-1],\n            #     'val_loss': val_loss_plot[-1],\n            # }\n            \n            # checkpoint_filename = checkpoint_path.format(epoch)\n            # torch.save(checkpoint, checkpoint_filename)\n            \n            if save_best and val_loss_plot[-1] < best_val_loss: # instead of val_loss and best_val loss we should use accuracy!!!\n                #create checkpoint\n                checkpoint = {\n                'epoch': epoch,\n                'model_state_dict': generator.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': loss_plot[-1],\n                'val_loss': val_loss_plot[-1],\n                }\n                \n                #save checkpoint only if it is better than the previous ones\n                checkpoint_filename = checkpoint_path.format(epoch)\n                torch.save(checkpoint, checkpoint_filename)\n                \n                #update best model\n                best_val_loss = val_loss_plot[-1]\n                best_checkpoint_filename = checkpoint_path.format('best')\n                torch.save(checkpoint, best_checkpoint_filename)\n        \n        \n    return loss_plot, val_loss_plot,acc_plot, val_acc_plot #,acc_plot, val_acc_plot,","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:11:08.323779Z","iopub.execute_input":"2024-01-18T23:11:08.324171Z","iopub.status.idle":"2024-01-18T23:11:08.340554Z","shell.execute_reply.started":"2024-01-18T23:11:08.324141Z","shell.execute_reply":"2024-01-18T23:11:08.339393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Simple CNN:\ngenerator=GeneratorResNet(3,4,1).to(device)#Decoder(3).to(device)\ninit_weights(generator, 'normal', scaling=0.0125)\nprint(generator)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:48:45.075324Z","iopub.execute_input":"2024-01-18T23:48:45.075720Z","iopub.status.idle":"2024-01-18T23:48:45.131835Z","shell.execute_reply.started":"2024-01-18T23:48:45.075690Z","shell.execute_reply":"2024-01-18T23:48:45.130888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''#General CNN\nhidden_sizes=[64,128,256] #Numero di kernel per hidden layer\nkernels=[3,3,3,3] #dimensione dei kernel per ogni layer (compreso l'output)\nbn=[True,True,True] #True -> Batch Normalization nel hidden layer corrispondente\ndrop=[0.3,0.3,0.3] # Dropout with p[i]=drop[i]\ngenerator=make_conv_net(hidden_sizes, kernels, 3, 1,bn,drop).to(device)\ninit_weights(generator, 'normal', scaling=0.005)\nprint(generator)'''","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:48:45.784073Z","iopub.execute_input":"2024-01-18T23:48:45.784462Z","iopub.status.idle":"2024-01-18T23:48:45.791003Z","shell.execute_reply.started":"2024-01-18T23:48:45.784433Z","shell.execute_reply":"2024-01-18T23:48:45.790013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in(tqdm(test_dataloader)):\n    generated=generate_data(generator,batch)\n    break\ngenerated[1,0].shape\n#batch=transform(batch)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:48:50.374644Z","iopub.execute_input":"2024-01-18T23:48:50.375497Z","iopub.status.idle":"2024-01-18T23:48:50.411112Z","shell.execute_reply.started":"2024-01-18T23:48:50.375462Z","shell.execute_reply":"2024-01-18T23:48:50.410083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:48:50.763789Z","iopub.execute_input":"2024-01-18T23:48:50.764182Z","iopub.status.idle":"2024-01-18T23:48:50.770716Z","shell.execute_reply.started":"2024-01-18T23:48:50.764146Z","shell.execute_reply":"2024-01-18T23:48:50.769711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qplt_g=generated[3,0].detach().cpu().numpy()\nqplt_r=batch[3,0].detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:48:53.281767Z","iopub.execute_input":"2024-01-18T23:48:53.282139Z","iopub.status.idle":"2024-01-18T23:48:53.287803Z","shell.execute_reply.started":"2024-01-18T23:48:53.282111Z","shell.execute_reply":"2024-01-18T23:48:53.286730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.imshow(qplt_g, aspect='auto', extent=[0, 16/3, 10, 150])\nplt.title('Generated - pre training')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:48:53.595226Z","iopub.execute_input":"2024-01-18T23:48:53.595624Z","iopub.status.idle":"2024-01-18T23:48:54.194467Z","shell.execute_reply.started":"2024-01-18T23:48:53.595593Z","shell.execute_reply":"2024-01-18T23:48:54.193472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.imshow(qplt_r, aspect='auto')\nplt.title('Real')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:48:59.500674Z","iopub.execute_input":"2024-01-18T23:48:59.501077Z","iopub.status.idle":"2024-01-18T23:49:00.069617Z","shell.execute_reply.started":"2024-01-18T23:48:59.501047Z","shell.execute_reply":"2024-01-18T23:49:00.068641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss function, learning rate, and optimiser\n\nl2_loss = nn.MSELoss() #this is l2!!!\nl1_loss = nn.L1Loss()  #this is L1!!!\nloss=l1_loss#LogCoshLoss()\nlr=0.0001\n\nG_optimizer = torch.optim.Adam(generator.parameters(), lr=lr )","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:49:46.907201Z","iopub.execute_input":"2024-01-18T23:49:46.907930Z","iopub.status.idle":"2024-01-18T23:49:46.914964Z","shell.execute_reply.started":"2024-01-18T23:49:46.907898Z","shell.execute_reply":"2024-01-18T23:49:46.913950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_checkpoint='/kaggle/working/generator_unet_weights_test.checkpoint_epoch_{}.pth'\nn_epochs=50","metadata":{"execution":{"iopub.status.busy":"2024-01-18T23:49:53.081144Z","iopub.execute_input":"2024-01-18T23:49:53.081904Z","iopub.status.idle":"2024-01-18T23:49:53.086059Z","shell.execute_reply.started":"2024-01-18T23:49:53.081872Z","shell.execute_reply":"2024-01-18T23:49:53.085036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_plot, val_loss_plot,acc_plot, val_acc_plot=train_decoder(n_epochs,generator,loss,G_optimizer,dataloader,test_dataloader,calculate_iou_2d,save_checkpoint)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-01-18T23:49:53.331700Z","iopub.execute_input":"2024-01-18T23:49:53.332084Z","iopub.status.idle":"2024-01-19T00:33:16.929629Z","shell.execute_reply.started":"2024-01-18T23:49:53.332055Z","shell.execute_reply":"2024-01-19T00:33:16.928643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save model in native PyTorch format (.pth or .pt)\ntorch.save(generator.state_dict(), '/kaggle/working/ResnetMaxpreproc_test.pth')\nprint('Model saved')","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:01.925207Z","iopub.execute_input":"2024-01-19T00:35:01.926079Z","iopub.status.idle":"2024-01-19T00:35:01.966721Z","shell.execute_reply.started":"2024-01-19T00:35:01.926048Z","shell.execute_reply":"2024-01-19T00:35:01.965774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the loss\nimport matplotlib.pyplot as plt\nplt.plot(loss_plot,color='b',label='train')\nplt.plot(val_loss_plot,color='r',label='validation')\n#plt.title('L1 loss vs epoch - 100 Data Standardised and resampled')\nplt.legend()\nplt.savefig('lc.pdf')\n#plt.yscale('log')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:02.294426Z","iopub.execute_input":"2024-01-19T00:35:02.294756Z","iopub.status.idle":"2024-01-19T00:35:02.902678Z","shell.execute_reply.started":"2024-01-19T00:35:02.294730Z","shell.execute_reply":"2024-01-19T00:35:02.901706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in(tqdm(test_dataloader)):\n    generated=generate_data(generator,batch)\n    break\ngenerated[0,0].shape","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:30.421086Z","iopub.execute_input":"2024-01-19T00:35:30.421540Z","iopub.status.idle":"2024-01-19T00:35:30.458547Z","shell.execute_reply.started":"2024-01-19T00:35:30.421507Z","shell.execute_reply":"2024-01-19T00:35:30.457395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qplt_g=generated[0,0].detach().cpu().numpy()\nqplt_r=batch[0,0].detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:34.516574Z","iopub.execute_input":"2024-01-19T00:35:34.516960Z","iopub.status.idle":"2024-01-19T00:35:34.522676Z","shell.execute_reply.started":"2024-01-19T00:35:34.516930Z","shell.execute_reply":"2024-01-19T00:35:34.521696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.imshow(qplt_g, aspect='auto', extent=[0, 16/3, 10, 150])\nplt.title('Generated - 10 epochs')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:35.148740Z","iopub.execute_input":"2024-01-19T00:35:35.149126Z","iopub.status.idle":"2024-01-19T00:35:35.648931Z","shell.execute_reply.started":"2024-01-19T00:35:35.149096Z","shell.execute_reply":"2024-01-19T00:35:35.648025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.imshow(qplt_r, aspect='auto',)\nplt.title('Real')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:39.454182Z","iopub.execute_input":"2024-01-19T00:35:39.455025Z","iopub.status.idle":"2024-01-19T00:35:39.884083Z","shell.execute_reply.started":"2024-01-19T00:35:39.454989Z","shell.execute_reply":"2024-01-19T00:35:39.883306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.imshow(np.abs(qplt_r-qplt_g), aspect='auto',cmap='viridis',vmax=1)\nplt.title('abs(real-gen)')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:42.344772Z","iopub.execute_input":"2024-01-19T00:35:42.345635Z","iopub.status.idle":"2024-01-19T00:35:42.777439Z","shell.execute_reply.started":"2024-01-19T00:35:42.345605Z","shell.execute_reply":"2024-01-19T00:35:42.776431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ndata=10\nfig, axes = plt.subplots(nrows=ndata, ncols=3, figsize=[30, 8 * ndata])\naxes[0,0].set_title('True')\naxes[0,1].set_title('Generated')\naxes[0,2].set_title('|True-Generated|')\nfor i in range(ndata):\n    qplt_g=generated[i,0].detach().cpu().numpy()\n    qplt_r=batch[i,0].detach().cpu().numpy()\n    axes[i, 0].imshow(qplt_r, cmap='viridis', aspect='auto',vmax=1  )\n    axes[i, 1].imshow(qplt_g, cmap='viridis', aspect='auto',vmax=1  )\n    axes[i, 2].imshow(np.abs(qplt_r-qplt_g), cmap='viridis', aspect='auto',vmax=1 )\n\n    #axes[i, 0].set_xscale('seconds')\n    #axes[i, 0].set_yscale('log', base=2)\n    #axes[i, 0].set_ylim(10, 150)\n    axes[i, 0].set_ylabel('Frequency [Hz]')\n    axes[i, 0].set_xlabel('Time [seconds]')\n\n    #axes[i, 1].set_xscale('seconds')\n    #axes[i, 1].set_yscale('log', base=2)\n    #axes[i, 1].set_ylim(10, 150)\n    axes[i, 1].set_ylabel('Frequency [Hz]')\n    axes[i, 1].set_xlabel('Time [seconds]')\n    \n    #axes[i, 2].set_xscale('seconds')\n    #axes[i, 2].set_yscale('log', base=2)\n    #axes[i, 2].set_ylim(10, 150)\n    axes[i, 2].set_ylabel('Frequency [Hz]')\n    axes[i, 2].set_xlabel('Time [seconds]')\n\n#plt.colorbar()\n    \nplt.savefig('ResnetMaxpreproc.pdf')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T00:35:51.568315Z","iopub.execute_input":"2024-01-19T00:35:51.569063Z","iopub.status.idle":"2024-01-19T00:36:05.779631Z","shell.execute_reply.started":"2024-01-19T00:35:51.569031Z","shell.execute_reply":"2024-01-19T00:36:05.778587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting The Syntetic Signals","metadata":{"tags":[]}},{"cell_type":"markdown","source":"### Load Checkpoint","metadata":{}},{"cell_type":"code","source":"'''# Define the path to your checkpoint file\ncheckpoint_path = '/home/jovyan/checkpoints/checkpoint_epoch_best.pth'\n\n# Load the checkpoint\ncheckpoint = torch.load(checkpoint_path)\n\n# Load the model state from the checkpoint\ngenerator.load_state_dict(checkpoint['model_state_dict'])'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}