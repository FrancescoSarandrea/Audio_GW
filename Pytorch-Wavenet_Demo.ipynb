{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xRwPOG3-dMRopLE-VnGyN29H-TL-u2bz","timestamp":1696926478700}],"authorship_tag":"ABX9TyPDbSZqo192uuFDFQg6wh8+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["A notebook to run an example of WaveNet. All the needed classes are copied in the file directly, without the need to import them from the git."],"metadata":{"id":"UPW_ymGYuCTs"}},{"cell_type":"markdown","source":["# Utility"],"metadata":{"id":"vezvhVWcb9ul"}},{"cell_type":"code","source":["!pip install gwpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"muXmYcnDgZyi","executionInfo":{"status":"ok","timestamp":1696939758045,"user_tz":-120,"elapsed":4815,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}},"outputId":"e61918f8-09fd-4759-fcc2-63864b7ea0ad"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gwpy in /usr/local/lib/python3.10/dist-packages (3.0.7)\n","Requirement already satisfied: astropy>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gwpy) (5.3.4)\n","Requirement already satisfied: dqsegdb2 in /usr/local/lib/python3.10/dist-packages (from gwpy) (1.2.1)\n","Requirement already satisfied: gwdatafind>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gwpy) (1.1.3)\n","Requirement already satisfied: gwosc>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from gwpy) (0.7.1)\n","Requirement already satisfied: h5py>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from gwpy) (3.9.0)\n","Requirement already satisfied: ligo-segments>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gwpy) (1.4.0)\n","Requirement already satisfied: ligotimegps>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from gwpy) (2.0.1)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from gwpy) (3.7.1)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from gwpy) (1.23.5)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from gwpy) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gwpy) (2.31.0)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from gwpy) (1.11.3)\n","Requirement already satisfied: tqdm>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from gwpy) (4.66.1)\n","Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy>=4.3.0->gwpy) (2.0.0.3)\n","Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy>=4.3.0->gwpy) (6.0.1)\n","Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from astropy>=4.3.0->gwpy) (23.2)\n","Requirement already satisfied: igwn-auth-utils>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from gwdatafind>=1.1.0->gwpy) (1.0.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ligo-segments>=1.0.0->gwpy) (1.16.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->gwpy) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->gwpy) (0.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->gwpy) (4.43.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->gwpy) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->gwpy) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->gwpy) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gwpy) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gwpy) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gwpy) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gwpy) (2023.7.22)\n","Requirement already satisfied: cryptography>=2.3 in /usr/local/lib/python3.10/dist-packages (from igwn-auth-utils>=0.3.1->gwdatafind>=1.1.0->gwpy) (41.0.4)\n","Requirement already satisfied: safe-netrc>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from igwn-auth-utils>=0.3.1->gwdatafind>=1.1.0->gwpy) (1.0.1)\n","Requirement already satisfied: scitokens>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from igwn-auth-utils>=0.3.1->gwdatafind>=1.1.0->gwpy) (1.8.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.3->igwn-auth-utils>=0.3.1->gwdatafind>=1.1.0->gwpy) (1.16.0)\n","Requirement already satisfied: PyJWT>=1.6.1 in /usr/lib/python3/dist-packages (from scitokens>=1.7.0->igwn-auth-utils>=0.3.1->gwdatafind>=1.1.0->gwpy) (2.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.3->igwn-auth-utils>=0.3.1->gwdatafind>=1.1.0->gwpy) (2.21)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OAW0DouAtwTa","executionInfo":{"status":"ok","timestamp":1696939776395,"user_tz":-120,"elapsed":10398,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"outputs":[],"source":["import os\n","import h5py as h5\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from os import listdir\n","import numpy as np\n","import pandas as pd\n","import threading\n","import math\n","import time\n","\n","import tensorflow as tf\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchaudio\n","import sys\n","from torch.utils.data import DataLoader, TensorDataset\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from torchsummary import summary\n","import torchvision\n","from sklearn.model_selection import train_test_split\n","\n","from gwpy.timeseries import TimeSeries"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import Parameter\n","from torch.autograd import Variable, Function"],"metadata":{"id":"tDlYkISHqWpd","executionInfo":{"status":"ok","timestamp":1696940623210,"user_tz":-120,"elapsed":323,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def dilate(x, dilation, init_dilation=1, pad_start=True):\n","    \"\"\"\n","    :param x: Tensor of size (N, C, L), where N is the input dilation, C is the number of channels, and L is the input length\n","    :param dilation: Target dilation. Will be the size of the first dimension of the output tensor.\n","    :param pad_start: If the input length is not compatible with the specified dilation, zero padding is used. This parameter determines wether the zeros are added at the start or at the end.\n","    :return: The dilated tensor of size (dilation, C, L*N / dilation). The output might be zero padded at the start\n","    \"\"\"\n","\n","    [n, c, l] = x.size()\n","    dilation_factor = dilation / init_dilation\n","    if dilation_factor == 1:\n","        return x\n","\n","    # zero padding for reshaping\n","    new_l = int(np.ceil(l / dilation_factor) * dilation_factor)\n","    if new_l != l:\n","        l = new_l\n","        x = constant_pad_1d(x, new_l, dimension=2, pad_start=pad_start)\n","\n","    l_old = int(round(l / dilation_factor))\n","    n_old = int(round(n * dilation_factor))\n","    l = math.ceil(l * init_dilation / dilation)\n","    n = math.ceil(n * dilation / init_dilation)\n","\n","    # reshape according to dilation\n","    x = x.permute(1, 2, 0).contiguous()  # (n, c, l) -> (c, l, n)\n","    x = x.view(c, l, n)\n","    x = x.permute(2, 0, 1).contiguous()  # (c, l, n) -> (n, c, l)\n","\n","    return x\n","\n","\n","class DilatedQueue:\n","    def __init__(self, max_length, data=None, dilation=1, num_deq=1, num_channels=1, dtype=torch.FloatTensor):\n","        self.in_pos = 0\n","        self.out_pos = 0\n","        self.num_deq = num_deq\n","        self.num_channels = num_channels\n","        self.dilation = dilation\n","        self.max_length = max_length\n","        self.data = data\n","        self.dtype = dtype\n","        if data == None:\n","            self.data = Variable(dtype(num_channels, max_length).zero_())\n","\n","    def enqueue(self, input):\n","        self.data[:, self.in_pos] = input\n","        self.in_pos = (self.in_pos + 1) % self.max_length\n","\n","    def dequeue(self, num_deq=1, dilation=1):\n","        #       |\n","        #  |6|7|8|1|2|3|4|5|\n","        #         |\n","        start = self.out_pos - ((num_deq - 1) * dilation)\n","        if start < 0:\n","            t1 = self.data[:, start::dilation]\n","            t2 = self.data[:, self.out_pos % dilation:self.out_pos + 1:dilation]\n","            t = torch.cat((t1, t2), 1)\n","        else:\n","            t = self.data[:, start:self.out_pos + 1:dilation]\n","\n","        self.out_pos = (self.out_pos + 1) % self.max_length\n","        return t\n","\n","    def reset(self):\n","        self.data = Variable(self.dtype(self.num_channels, self.max_length).zero_())\n","        self.in_pos = 0\n","        self.out_pos = 0\n","\n","\n","class ConstantPad1d(Function):\n","    def __init__(self, target_size, dimension=0, value=0, pad_start=False):\n","        super(ConstantPad1d, self).__init__()\n","        self.target_size = target_size\n","        self.dimension = dimension\n","        self.value = value\n","        self.pad_start = pad_start\n","\n","    def forward(self, input):\n","        self.num_pad = self.target_size - input.size(self.dimension)\n","        assert self.num_pad >= 0, 'target size has to be greater than input size'\n","\n","        self.input_size = input.size()\n","\n","        size = list(input.size())\n","        size[self.dimension] = self.target_size\n","        output = input.new(*tuple(size)).fill_(self.value)\n","        c_output = output\n","\n","        # crop output\n","        if self.pad_start:\n","            c_output = c_output.narrow(self.dimension, self.num_pad, c_output.size(self.dimension) - self.num_pad)\n","        else:\n","            c_output = c_output.narrow(self.dimension, 0, c_output.size(self.dimension) - self.num_pad)\n","\n","        c_output.copy_(input)\n","        return output\n","\n","    def backward(self, grad_output):\n","        grad_input = grad_output.new(*self.input_size).zero_()\n","        cg_output = grad_output\n","\n","        # crop grad_output\n","        if self.pad_start:\n","            cg_output = cg_output.narrow(self.dimension, self.num_pad, cg_output.size(self.dimension) - self.num_pad)\n","        else:\n","            cg_output = cg_output.narrow(self.dimension, 0, cg_output.size(self.dimension) - self.num_pad)\n","\n","        grad_input.copy_(cg_output)\n","        return grad_input\n","\n","\n","def constant_pad_1d(input,\n","                    target_size,\n","                    dimension=0,\n","                    value=0,\n","                    pad_start=False):\n","    return ConstantPad1d(target_size, dimension, value, pad_start)(input)"],"metadata":{"id":"RYvzZiq5qNhC","executionInfo":{"status":"ok","timestamp":1696940625227,"user_tz":-120,"elapsed":236,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class WaveNetModel(nn.Module):\n","    \"\"\"\n","    A Complete Wavenet Model\n","\n","    Args:\n","        layers (Int):               Number of layers in each block\n","        blocks (Int):               Number of wavenet blocks of this model\n","        dilation_channels (Int):    Number of channels for the dilated convolution\n","        residual_channels (Int):    Number of channels for the residual connection\n","        skip_channels (Int):        Number of channels for the skip connections\n","        classes (Int):              Number of possible values each sample can have\n","        output_length (Int):        Number of samples that are generated for each input\n","        kernel_size (Int):          Size of the dilation kernel\n","        dtype:                      Parameter type of this model\n","\n","    Shape:\n","        - Input: :math:`(N, C_{in}, L_{in})`\n","        - Output: :math:`()`\n","        L should be the length of the receptive field\n","    \"\"\"\n","    def __init__(self,\n","                 layers=10,\n","                 blocks=4,\n","                 dilation_channels=32,\n","                 residual_channels=32,\n","                 skip_channels=256,\n","                 end_channels=256,\n","                 classes=256,\n","                 output_length=32,\n","                 kernel_size=2,\n","                 dtype=torch.FloatTensor,\n","                 bias=False):\n","\n","        super(WaveNetModel, self).__init__()\n","\n","        self.layers = layers\n","        self.blocks = blocks\n","        self.dilation_channels = dilation_channels\n","        self.residual_channels = residual_channels\n","        self.skip_channels = skip_channels\n","        self.classes = classes\n","        self.kernel_size = kernel_size\n","        self.dtype = dtype\n","\n","        # build model\n","        receptive_field = 1\n","        init_dilation = 1\n","\n","        self.dilations = []\n","        self.dilated_queues = []\n","        # self.main_convs = nn.ModuleList()\n","        self.filter_convs = nn.ModuleList()\n","        self.gate_convs = nn.ModuleList()\n","        self.residual_convs = nn.ModuleList()\n","        self.skip_convs = nn.ModuleList()\n","\n","        # 1x1 convolution to create channels\n","        self.start_conv = nn.Conv1d(in_channels=self.classes,\n","                                    out_channels=residual_channels,\n","                                    kernel_size=1,\n","                                    bias=bias)\n","\n","        for b in range(blocks):\n","            additional_scope = kernel_size - 1\n","            new_dilation = 1\n","            for i in range(layers):\n","                # dilations of this layer\n","                self.dilations.append((new_dilation, init_dilation))\n","\n","                # dilated queues for fast generation\n","                self.dilated_queues.append(DilatedQueue(max_length=(kernel_size - 1) * new_dilation + 1,\n","                                                        num_channels=residual_channels,\n","                                                        dilation=new_dilation,\n","                                                        dtype=dtype))\n","\n","                # dilated convolutions\n","                self.filter_convs.append(nn.Conv1d(in_channels=residual_channels,\n","                                                   out_channels=dilation_channels,\n","                                                   kernel_size=kernel_size,\n","                                                   bias=bias))\n","\n","                self.gate_convs.append(nn.Conv1d(in_channels=residual_channels,\n","                                                 out_channels=dilation_channels,\n","                                                 kernel_size=kernel_size,\n","                                                 bias=bias))\n","\n","                # 1x1 convolution for residual connection\n","                self.residual_convs.append(nn.Conv1d(in_channels=dilation_channels,\n","                                                     out_channels=residual_channels,\n","                                                     kernel_size=1,\n","                                                     bias=bias))\n","\n","                # 1x1 convolution for skip connection\n","                self.skip_convs.append(nn.Conv1d(in_channels=dilation_channels,\n","                                                 out_channels=skip_channels,\n","                                                 kernel_size=1,\n","                                                 bias=bias))\n","\n","                receptive_field += additional_scope\n","                additional_scope *= 2\n","                init_dilation = new_dilation\n","                new_dilation *= 2\n","\n","        self.end_conv_1 = nn.Conv1d(in_channels=skip_channels,\n","                                  out_channels=end_channels,\n","                                  kernel_size=1,\n","                                  bias=True)\n","\n","        self.end_conv_2 = nn.Conv1d(in_channels=end_channels,\n","                                    out_channels=classes,\n","                                    kernel_size=1,\n","                                    bias=True)\n","\n","        # self.output_length = 2 ** (layers - 1)\n","        self.output_length = output_length\n","        self.receptive_field = receptive_field\n","\n","    @staticmethod\n","    def wavenet(self, input, dilation_func):\n","\n","        x = self.start_conv(input)\n","        skip = 0\n","\n","        # WaveNet layers\n","        for i in range(self.blocks * self.layers):\n","\n","            #            |----------------------------------------|     *residual*\n","            #            |                                        |\n","            #            |    |-- conv -- tanh --|                |\n","            # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n","            #                 |-- conv -- sigm --|     |\n","            #                                         1x1\n","            #                                          |\n","            # ---------------------------------------> + ------------->\t*skip*\n","\n","            (dilation, init_dilation) = self.dilations[i]\n","\n","            residual = dilation_func(x, dilation, init_dilation, i)\n","\n","            # dilated convolution\n","            filter = self.filter_convs[i](residual)\n","            filter = F.tanh(filter)\n","            gate = self.gate_convs[i](residual)\n","            gate = F.sigmoid(gate)\n","            x = filter * gate\n","\n","            # parametrized skip connection\n","            s = x\n","            if x.size(2) != 1:\n","                 s = dilate(x, 1, init_dilation=dilation)\n","            s = self.skip_convs[i](s)\n","            try:\n","                skip = skip[:, :, -s.size(2):]\n","            except:\n","                skip = 0\n","            skip = s + skip\n","\n","            x = self.residual_convs[i](x)\n","            x = x + residual[:, :, (self.kernel_size - 1):]\n","\n","        x = F.relu(skip)\n","        x = F.relu(self.end_conv_1(x))\n","        x = self.end_conv_2(x)\n","\n","        return x\n","\n","    @staticmethod\n","    def wavenet_dilate(self, input, dilation, init_dilation, i):\n","        x = dilate(input, dilation, init_dilation)\n","        return x\n","\n","    @staticmethod\n","    def queue_dilate(self, input, dilation, init_dilation, i):\n","        queue = self.dilated_queues[i]\n","        queue.enqueue(input.data[0])\n","        x = queue.dequeue(num_deq=self.kernel_size,\n","                          dilation=dilation)\n","        x = x.unsqueeze(0)\n","\n","        return x\n","\n","    @staticmethod\n","    def forward(self, input):\n","        x = self.wavenet(input,\n","                         dilation_func=self.wavenet_dilate)\n","\n","        # reshape output\n","        [n, c, l] = x.size()\n","        l = self.output_length\n","        x = x[:, :, -l:]\n","        x = x.transpose(1, 2).contiguous()\n","        x = x.view(n * l, c)\n","        return x\n","\n","    @staticmethod\n","    def generate(self,\n","                 num_samples,\n","                 first_samples=None,\n","                 temperature=1.):\n","        self.eval()\n","        if first_samples is None:\n","            first_samples = self.dtype(1).zero_()\n","        generated = Variable(first_samples, volatile=True)\n","\n","        num_pad = self.receptive_field - generated.size(0)\n","        if num_pad > 0:\n","            generated = constant_pad_1d(generated, self.scope, pad_start=True)\n","            print(\"pad zero\")\n","\n","        for i in range(num_samples):\n","            input = Variable(torch.FloatTensor(1, self.classes, self.receptive_field).zero_())\n","            input = input.scatter_(1, generated[-self.receptive_field:].view(1, -1, self.receptive_field), 1.)\n","\n","            x = self.wavenet(input,\n","                             dilation_func=self.wavenet_dilate)[:, :, -1].squeeze()\n","\n","            if temperature > 0:\n","                x /= temperature\n","                prob = F.softmax(x, dim=0)\n","                prob = prob.cpu()\n","                np_prob = prob.data.numpy()\n","                x = np.random.choice(self.classes, p=np_prob)\n","                x = Variable(torch.LongTensor([x]))#np.array([x])\n","            else:\n","                x = torch.max(x, 0)[1].float()\n","\n","            generated = torch.cat((generated, x), 0)\n","\n","        generated = (generated / self.classes) * 2. - 1\n","        mu_gen = mu_law_expansion(generated, self.classes)\n","\n","        self.train()\n","        return mu_gen\n","\n","    @staticmethod\n","    def generate_fast(self,\n","                      num_samples,\n","                      first_samples=None,\n","                      temperature=1.,\n","                      regularize=0.,\n","                      progress_callback=None,\n","                      progress_interval=100):\n","        self.eval()\n","        if first_samples is None:\n","            first_samples = torch.LongTensor(1).zero_() + (self.classes // 2)\n","        first_samples = Variable(first_samples)\n","\n","        # reset queues\n","        for queue in self.dilated_queues:\n","            queue.reset()\n","\n","        num_given_samples = first_samples.size(0)\n","        total_samples = num_given_samples + num_samples\n","\n","        input = Variable(torch.FloatTensor(1, self.classes, 1).zero_())\n","        input = input.scatter_(1, first_samples[0:1].view(1, -1, 1), 1.)\n","\n","        # fill queues with given samples\n","        for i in range(num_given_samples - 1):\n","            x = self.wavenet(input,\n","                             dilation_func=self.queue_dilate)\n","            input.zero_()\n","            input = input.scatter_(1, first_samples[i + 1:i + 2].view(1, -1, 1), 1.).view(1, self.classes, 1)\n","\n","            # progress feedback\n","            if i % progress_interval == 0:\n","                if progress_callback is not None:\n","                    progress_callback(i, total_samples)\n","\n","        # generate new samples\n","        generated = np.array([])\n","        regularizer = torch.pow(Variable(torch.arange(self.classes)) - self.classes / 2., 2)\n","        regularizer = regularizer.squeeze() * regularize\n","        tic = time.time()\n","        for i in range(num_samples):\n","            x = self.wavenet(input,\n","                             dilation_func=self.queue_dilate).squeeze()\n","\n","            x -= regularizer\n","\n","            if temperature > 0:\n","                # sample from softmax distribution\n","                x /= temperature\n","                prob = F.softmax(x, dim=0)\n","                prob = prob.cpu()\n","                np_prob = prob.data.numpy()\n","                x = np.random.choice(self.classes, p=np_prob)\n","                x = np.array([x])\n","            else:\n","                # convert to sample value\n","                x = torch.max(x, 0)[1][0]\n","                x = x.cpu()\n","                x = x.data.numpy()\n","\n","            o = (x / self.classes) * 2. - 1\n","            generated = np.append(generated, o)\n","\n","            # set new input\n","            x = Variable(torch.from_numpy(x).type(torch.LongTensor))\n","            input.zero_()\n","            input = input.scatter_(1, x.view(1, -1, 1), 1.).view(1, self.classes, 1)\n","\n","            if (i+1) == 100:\n","                toc = time.time()\n","                print(\"one generating step does take approximately \" + str((toc - tic) * 0.01) + \" seconds)\")\n","\n","            # progress feedback\n","            if (i + num_given_samples) % progress_interval == 0:\n","                if progress_callback is not None:\n","                    progress_callback(i + num_given_samples, total_samples)\n","\n","        self.train()\n","        mu_gen = mu_law_expansion(generated, self.classes)\n","        return mu_gen\n","\n","    def parameter_count(self):\n","        par = list(self.parameters())\n","        s = sum([np.prod(list(d.size())) for d in par])\n","        return s\n","\n","    def cpu(self, type=torch.FloatTensor):\n","        self.dtype = type\n","        for q in self.dilated_queues:\n","            q.dtype = self.dtype\n","        super().cpu()\n","\n","\n","def load_latest_model_from(location, use_cuda=True):\n","    files = [location + \"/\" + f for f in os.listdir(location)]\n","    newest_file = max(files, key=os.path.getctime)\n","    print(\"load model \" + newest_file)\n","\n","    if use_cuda:\n","        model = torch.load(newest_file)\n","    else:\n","        model = load_to_cpu(newest_file)\n","\n","    return model\n","\n","\n","def load_to_cpu(path):\n","    model = torch.load(path, map_location=lambda storage, loc: storage)\n","    model.cpu()\n","    return model"],"metadata":{"id":"luCre0AHgAG6","executionInfo":{"status":"ok","timestamp":1696940627998,"user_tz":-120,"elapsed":246,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class Logger:\n","    def __init__(self,\n","                 log_interval=50,\n","                 validation_interval=200,\n","                 generate_interval=500,\n","                 trainer=None,\n","                 generate_function=None):\n","        self.trainer = trainer\n","        self.log_interval = log_interval\n","        self.validation_interval = validation_interval\n","        self.generate_interval = generate_interval\n","        self.accumulated_loss = 0\n","        self.generate_function = generate_function\n","        if self.generate_function is not None:\n","            self.generate_thread = threading.Thread(target=self.generate_function)\n","            self.generate_function.daemon = True\n","\n","    def log(self, current_step, current_loss):\n","        self.accumulated_loss += current_loss\n","        if current_step % self.log_interval == 0:\n","            self.log_loss(current_step)\n","            self.accumulated_loss = 0\n","        if current_step % self.validation_interval == 0:\n","            self.validate(current_step)\n","        if current_step % self.generate_interval == 0:\n","            self.generate(current_step)\n","\n","    def log_loss(self, current_step):\n","        avg_loss = self.accumulated_loss / self.log_interval\n","        print(\"loss at step \" + str(current_step) + \": \" + str(avg_loss))\n","\n","    def validate(self, current_step):\n","        avg_loss, avg_accuracy = self.trainer.validate()\n","        print(\"validation loss: \" + str(avg_loss))\n","        print(\"validation accuracy: \" + str(avg_accuracy * 100) + \"%\")\n","\n","    def generate(self, current_step):\n","        if self.generate_function is None:\n","            return\n","\n","        if self.generate_thread.is_alive():\n","            print(\"Last generate is still running, skipping this one\")\n","        else:\n","            self.generate_thread = threading.Thread(target=self.generate_function,\n","                                                    args=[current_step])\n","            self.generate_thread.daemon = True\n","            self.generate_thread.start()\n","\n","\n","# Code referenced from https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514\n","class TensorboardLogger(Logger):\n","    def __init__(self,\n","                 log_interval=50,\n","                 validation_interval=200,\n","                 generate_interval=500,\n","                 trainer=None,\n","                 generate_function=None,\n","                 log_dir='logs'):\n","        super().__init__(log_interval, validation_interval, generate_interval, trainer, generate_function)\n","        #self.writer = tf.summary.FileWriter(log_dir)\n","        self.writer = tf.summary.create_file_writer(log_dir)\n","\n","    def log_loss(self, current_step):\n","        # loss\n","        avg_loss = self.accumulated_loss / self.log_interval\n","        self.scalar_summary('loss', avg_loss, current_step)\n","\n","        # parameter histograms\n","        for tag, value, in self.trainer.model.named_parameters():\n","            tag = tag.replace('.', '/')\n","            self.histo_summary(tag, value.data.cpu().numpy(), current_step)\n","            if value.grad is not None:\n","                self.histo_summary(tag + '/grad', value.grad.data.cpu().numpy(), current_step)\n","\n","    def validate(self, current_step):\n","        avg_loss, avg_accuracy = self.trainer.validate()\n","        self.scalar_summary('validation loss', avg_loss, current_step)\n","        self.scalar_summary('validation accuracy', avg_accuracy, current_step)\n","\n","    def log_audio(self, step):\n","        samples = self.generate_function()\n","        tf_samples = tf.convert_to_tensor(samples)\n","        self.audio_summary('audio sample', tf_samples, step, sr=16000)\n","\n","    def scalar_summary(self, tag, value, step):\n","        \"\"\"Log a scalar variable.\"\"\"\n","        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n","        self.writer.add_summary(summary, step)\n","\n","    def image_summary(self, tag, images, step):\n","        \"\"\"Log a list of images.\"\"\"\n","\n","        img_summaries = []\n","        for i, img in enumerate(images):\n","            # Write the image to a string\n","            try:\n","                s = StringIO()\n","            except:\n","                s = BytesIO()\n","            scipy.misc.toimage(img).save(s, format=\"png\")\n","\n","            # Create an Image object\n","            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n","                                       height=img.shape[0],\n","                                       width=img.shape[1])\n","            # Create a Summary value\n","            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n","\n","        # Create and write Summary\n","        summary = tf.Summary(value=img_summaries)\n","        self.writer.add_summary(summary, step)\n","\n","    def audio_summary(self, tag, sample, step, sr=16000):\n","        with tf.Session() as sess:\n","            audio_summary = tf.summary.audio(tag, sample, sample_rate=sr, max_outputs=4)\n","            summary = sess.run(audio_summary)\n","            self.writer.add_summary(summary, step)\n","            self.writer.flush()\n","\n","\n","    def histo_summary(self, tag, values, step, bins=200):\n","        \"\"\"Log a histogram of the tensor of values.\"\"\"\n","\n","        # Create a histogram using numpy\n","        counts, bin_edges = np.histogram(values, bins=bins)\n","\n","        # Fill the fields of the histogram proto\n","        hist = tf.HistogramProto()\n","        hist.min = float(np.min(values))\n","        hist.max = float(np.max(values))\n","        hist.num = int(np.prod(values.shape))\n","        hist.sum = float(np.sum(values))\n","        hist.sum_squares = float(np.sum(values ** 2))\n","\n","        # Drop the start of the first bin\n","        bin_edges = bin_edges[1:]\n","\n","        # Add bin edges and counts\n","        for edge in bin_edges:\n","            hist.bucket_limit.append(edge)\n","        for c in counts:\n","            hist.bucket.append(c)\n","\n","        # Create and write Summary\n","        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n","        self.writer.add_summary(summary, step)\n","        self.writer.flush()\n","\n","    def tensor_summary(self, tag, tensor, step):\n","        tf_tensor = tf.Variable(tensor).to_proto()\n","        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, tensor=tf_tensor)])\n","        #summary = tf.summary.tensor_summary(name=tag, tensor=tensor)\n","        self.writer.add_summary(summary, step)"],"metadata":{"id":"jB13S_1EhAae","executionInfo":{"status":"ok","timestamp":1696940630208,"user_tz":-120,"elapsed":444,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def print_last_loss(opt):\n","    print(\"loss: \", opt.losses[-1])\n","\n","\n","def print_last_validation_result(opt):\n","    print(\"validation loss: \", opt.validation_results[-1])\n","\n","\n","class WavenetTrainer:\n","    def __init__(self,\n","                 model,\n","                 dataset,\n","                 optimizer=optim.Adam,\n","                 lr=0.001,\n","                 weight_decay=0,\n","                 gradient_clipping=None,\n","                 logger=Logger(),\n","                 snapshot_path=None,\n","                 snapshot_name='snapshot',\n","                 snapshot_interval=1000,\n","                 dtype=torch.FloatTensor,\n","                 ltype=torch.LongTensor):\n","        self.model = model\n","        self.dataset = dataset\n","        self.dataloader = None\n","        self.lr = lr\n","        self.weight_decay = weight_decay\n","        self.clip = gradient_clipping\n","        self.optimizer_type = optimizer\n","        self.optimizer = self.optimizer_type(params=self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n","        self.logger = logger\n","        self.logger.trainer = self\n","        self.snapshot_path = snapshot_path\n","        self.snapshot_name = snapshot_name\n","        self.snapshot_interval = snapshot_interval\n","        self.dtype = dtype\n","        self.ltype = ltype\n","\n","    def train(self,\n","              batch_size=32,\n","              epochs=10,\n","              continue_training_at_step=0):\n","        self.model.train()\n","        self.dataloader = torch.utils.data.DataLoader(self.dataset,\n","                                                      batch_size=batch_size,\n","                                                      shuffle=True,\n","                                                      num_workers=8,\n","                                                      pin_memory=False)\n","        step = continue_training_at_step\n","        for current_epoch in range(epochs):\n","            print(\"epoch\", current_epoch)\n","            tic = time.time()\n","            for (x, target) in iter(self.dataloader):\n","                x = Variable(x.type(self.dtype))\n","                print('x '+str(x))\n","                target = Variable(target.view(-1).type(self.ltype))\n","\n","                output = self.model(x)\n","                loss = F.cross_entropy(output.squeeze(), target.squeeze())\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                loss = loss.data[0]\n","\n","                if self.clip is not None:\n","                    torch.nn.utils.clip_grad_norm(self.model.parameters(), self.clip)\n","                self.optimizer.step()\n","                step += 1\n","\n","                # time step duration:\n","                if step == 100:\n","                    toc = time.time()\n","                    print(\"one training step does take approximately \" + str((toc - tic) * 0.01) + \" seconds)\")\n","\n","                if step % self.snapshot_interval == 0:\n","                    if self.snapshot_path is None:\n","                        continue\n","                    time_string = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.gmtime())\n","                    torch.save(self.model, self.snapshot_path + '/' + self.snapshot_name + '_' + time_string)\n","\n","                self.logger.log(step, loss)\n","\n","    def validate(self):\n","        self.model.eval()\n","        self.dataset.train = False\n","        total_loss = 0\n","        accurate_classifications = 0\n","        for (x, target) in iter(self.dataloader):\n","            x = Variable(x.type(self.dtype))\n","            target = Variable(target.view(-1).type(self.ltype))\n","\n","            output = self.model(x)\n","            loss = F.cross_entropy(output.squeeze(), target.squeeze())\n","            total_loss += loss.data[0]\n","\n","            predictions = torch.max(output, 1)[1].view(-1)\n","            correct_pred = torch.eq(target, predictions)\n","            accurate_classifications += torch.sum(correct_pred).data[0]\n","        # print(\"validate model with \" + str(len(self.dataloader.dataset)) + \" samples\")\n","        # print(\"average loss: \", total_loss / len(self.dataloader))\n","        avg_loss = total_loss / len(self.dataloader)\n","        avg_accuracy = accurate_classifications / (len(self.dataset)*self.dataset.target_length)\n","        self.dataset.train = True\n","        self.model.train()\n","        return avg_loss, avg_accuracy\n","\n","\n","def generate_audio(model,\n","                   length=8000,\n","                   temperatures=[0., 1.]):\n","    samples = []\n","    for temp in temperatures:\n","        samples.append(model.generate_fast(length, temperature=temp))\n","    samples = np.stack(samples, axis=0)\n","    return samples"],"metadata":{"id":"1ntXvUDagJPi","executionInfo":{"status":"ok","timestamp":1696940633287,"user_tz":-120,"elapsed":286,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["dtype = torch.FloatTensor\n","ltype = torch.LongTensor\n","\n","use_cuda = torch.cuda.is_available()\n","if use_cuda:\n","    print('use gpu')\n","    dtype = torch.cuda.FloatTensor\n","    ltype = torch.cuda.LongTensor"],"metadata":{"id":"F1MEjNxdpjWT","executionInfo":{"status":"ok","timestamp":1696940636336,"user_tz":-120,"elapsed":229,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class WavenetDataset(torch.utils.data.Dataset):\n","    def __init__(self,\n","                 dataset_file,\n","                 item_length,\n","                 target_length,\n","                 file_location=None,\n","                 classes=256,\n","                 sampling_rate=16000,\n","                 mono=True,\n","                 normalize=False,\n","                 dtype=np.uint8,\n","                 train=True,\n","                 test_stride=100):\n","\n","        #           |----receptive_field----|\n","        #                                 |--output_length--|\n","        # example:  | | | | | | | | | | | | | | | | | | | | |\n","        # target:                           | | | | | | | | | |\n","\n","        self.dataset_file = dataset_file\n","        self._item_length = item_length\n","        self._test_stride = test_stride\n","        self.target_length = target_length\n","        self.classes = classes\n","\n","        if not os.path.isfile(dataset_file):\n","            assert file_location is not None, \"no location for dataset files specified\"\n","            self.mono = mono\n","            self.normalize = normalize\n","\n","            self.sampling_rate = sampling_rate\n","            self.dtype = dtype\n","            self.create_dataset(file_location, dataset_file)\n","        else:\n","            # Unknown parameters of the stored dataset\n","            # TODO Can these parameters be stored, too?\n","            self.mono = None\n","            self.normalize = None\n","\n","            self.sampling_rate = None\n","            self.dtype = None\n","\n","        self.data = np.load(self.dataset_file, mmap_mode='r')\n","        self.start_samples = [0]\n","        self._length = 0\n","        self.calculate_length()\n","        self.train = train\n","        print(\"one hot input\")\n","        # assign every *test_stride*th item to the test set\n","\n","    def create_dataset(self, location, out_file):\n","        print(\"create dataset from audio files at\", location)\n","        self.dataset_file = out_file\n","        files = list_all_audio_files(location)\n","        processed_files = []\n","        for i, file in enumerate(files):\n","            print(\"  processed \" + str(i) + \" of \" + str(len(files)) + \" files\")\n","            file_data, _ = lr.load(path=file,\n","                                   sr=self.sampling_rate,\n","                                   mono=self.mono)\n","            if self.normalize:\n","                file_data = lr.util.normalize(file_data)\n","            quantized_data = quantize_data(file_data, self.classes).astype(self.dtype)\n","            processed_files.append(quantized_data)\n","\n","        np.savez(self.dataset_file, *processed_files)\n","\n","    def calculate_length(self):\n","        start_samples = [0]\n","        for i in range(len(self.data.keys())):\n","            start_samples.append(start_samples[-1] + len(self.data['arr_' + str(i)]))\n","        available_length = start_samples[-1] - (self._item_length - (self.target_length - 1)) - 1\n","        self._length = math.floor(available_length / self.target_length)\n","        self.start_samples = start_samples\n","\n","    def set_item_length(self, l):\n","        self._item_length = l\n","        self.calculate_length()\n","\n","    def __getitem__(self, idx):\n","        if self._test_stride < 2:\n","            sample_index = idx * self.target_length\n","        elif self.train:\n","            sample_index = idx * self.target_length + math.floor(idx / (self._test_stride-1))\n","        else:\n","            sample_index = self._test_stride * (idx+1) - 1\n","\n","        file_index = bisect.bisect_left(self.start_samples, sample_index) - 1\n","        if file_index < 0:\n","            file_index = 0\n","        if file_index + 1 >= len(self.start_samples):\n","            print(\"error: sample index \" + str(sample_index) + \" is to high. Results in file_index \" + str(file_index))\n","        position_in_file = sample_index - self.start_samples[file_index]\n","        end_position_in_next_file = sample_index + self._item_length + 1 - self.start_samples[file_index + 1]\n","\n","        if end_position_in_next_file < 0:\n","            file_name = 'arr_' + str(file_index)\n","            this_file = np.load(self.dataset_file, mmap_mode='r')[file_name]\n","            sample = this_file[position_in_file:position_in_file + self._item_length + 1]\n","        else:\n","            # load from two files\n","            file1 = np.load(self.dataset_file, mmap_mode='r')['arr_' + str(file_index)]\n","            file2 = np.load(self.dataset_file, mmap_mode='r')['arr_' + str(file_index + 1)]\n","            sample1 = file1[position_in_file:]\n","            sample2 = file2[:end_position_in_next_file]\n","            sample = np.concatenate((sample1, sample2))\n","\n","        example = torch.from_numpy(sample).type(torch.LongTensor)\n","        one_hot = torch.FloatTensor(self.classes, self._item_length).zero_()\n","        one_hot.scatter_(0, example[:self._item_length].unsqueeze(0), 1.)\n","        target = example[-self.target_length:].unsqueeze(0)\n","        return one_hot, target\n","\n","    def __len__(self):\n","        test_length = math.floor(self._length / self._test_stride)\n","        if self.train:\n","            return self._length - test_length\n","        else:\n","            return test_length\n","\n","\n","def quantize_data(data, classes):\n","    mu_x = mu_law_encoding(data, classes)\n","    bins = np.linspace(-1, 1, classes)\n","    quantized = np.digitize(mu_x, bins) - 1\n","    return quantized\n","\n","\n","def list_all_audio_files(location):\n","    audio_files = []\n","    for dirpath, dirnames, filenames in os.walk(location):\n","        for filename in [f for f in filenames if f.endswith((\".mp3\", \".wav\", \".aif\", \"aiff\"))]:\n","            audio_files.append(os.path.join(dirpath, filename))\n","\n","    if len(audio_files) == 0:\n","        print(\"found no audio files in \" + location)\n","    return audio_files\n","\n","\n","def mu_law_encoding(data, mu):\n","    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n","    return mu_x\n","\n","\n","def mu_law_expansion(data, mu):\n","    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n","    return s"],"metadata":{"id":"ZsLfJe0gx9X8","executionInfo":{"status":"ok","timestamp":1696933722461,"user_tz":-120,"elapsed":15,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":["# Demo Model"],"metadata":{"id":"j8i4cnQicI0I"}},{"cell_type":"code","source":["model = WaveNetModel(layers=6,\n","                     blocks=4,\n","                     dilation_channels=16,\n","                     residual_channels=16,\n","                     skip_channels=32,\n","                     output_length=8,\n","                     dtype=dtype,\n","                    bias=False)\n","#model = load_latest_model_from('snapshots', use_cuda=use_cuda)\n","\n","model.dtype = dtype\n","if use_cuda:\n","    model.cuda()\n","else:\n","    model.cpu()\n","print('model: ', model)\n","print('receptive field: ', model.receptive_field)\n","print('parameter count: ', model.parameter_count())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0P5S28GmpIFu","executionInfo":{"status":"ok","timestamp":1696940665995,"user_tz":-120,"elapsed":268,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}},"outputId":"70a36bdc-a572-43ea-ec9c-8f7f1f9c5eb5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["model:  WaveNetModel(\n","  (filter_convs): ModuleList(\n","    (0-23): 24 x Conv1d(16, 16, kernel_size=(2,), stride=(1,), bias=False)\n","  )\n","  (gate_convs): ModuleList(\n","    (0-23): 24 x Conv1d(16, 16, kernel_size=(2,), stride=(1,), bias=False)\n","  )\n","  (residual_convs): ModuleList(\n","    (0-23): 24 x Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n","  )\n","  (skip_convs): ModuleList(\n","    (0-23): 24 x Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n","  )\n","  (start_conv): Conv1d(256, 16, kernel_size=(1,), stride=(1,), bias=False)\n","  (end_conv_1): Conv1d(32, 256, kernel_size=(1,), stride=(1,))\n","  (end_conv_2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",")\n","receptive field:  253\n","parameter count:  121344\n"]}]},{"cell_type":"code","source":["def generate_and_log_samples(step):\n","    sample_length=4000\n","    gen_model = load_latest_model_from('snapshots')\n","    print(\"start generating...\")\n","    samples = generate_audio(gen_model,\n","                             length=sample_length,\n","                             temperatures=[0])\n","    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n","    logger.audio_summary('temperature 0', tf_samples, step, sr=16000)\n","\n","    samples = generate_audio(gen_model,\n","                             length=sample_length,\n","                             temperatures=[0.5])\n","    tf_samples = tf.convert_to_tensor(samples, dtype=tf.float32)\n","    logger.audio_summary('temperature 0.5', tf_samples, step, sr=16000)\n","    print(\"audio clips generated\")"],"metadata":{"id":"2TF7M02jsDIl","executionInfo":{"status":"ok","timestamp":1696933726977,"user_tz":-120,"elapsed":244,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":["data = WavenetDataset(dataset_file='train_samples/dataset.npz',\n","                      item_length=model.receptive_field + model.output_length - 1,\n","                      target_length=model.output_length,\n","                      file_location='train_samples',\n","                      test_stride=20)\n","print('the dataset has ' + str(len(data)) + ' items')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6C-fVsr8uwnh","executionInfo":{"status":"ok","timestamp":1696933728521,"user_tz":-120,"elapsed":17,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}},"outputId":"565f6917-4aae-48b0-88f6-aa9b9354ba10"},"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["one hot input\n","the dataset has 1139337 items\n"]}]},{"cell_type":"code","source":["logger = TensorboardLogger(log_interval=200,\n","                           validation_interval=400,\n","                           generate_interval=1000,\n","                           generate_function=generate_and_log_samples,\n","                           log_dir=\"logs/chaconne_model\")"],"metadata":{"id":"qW05J2ElhN3L","executionInfo":{"status":"ok","timestamp":1696933741676,"user_tz":-120,"elapsed":397,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["trainer = WavenetTrainer(model=model,\n","                         dataset=data,\n","                         lr=0.001,\n","                         snapshot_path='snapshots',\n","                         snapshot_name='chaconne_model',\n","                         snapshot_interval=1000,\n","                         logger=logger,\n","                         dtype=dtype,\n","                         ltype=ltype)"],"metadata":{"id":"BJqYHceThmqc","executionInfo":{"status":"ok","timestamp":1696933747751,"user_tz":-120,"elapsed":221,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["import bisect"],"metadata":{"id":"wb6Vn12Qy6JD","executionInfo":{"status":"ok","timestamp":1696928309205,"user_tz":-120,"elapsed":511,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["trainer.train(batch_size=16,\n","              epochs=10)"],"metadata":{"id":"AT2zcVF8oyNf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trying to Debug"],"metadata":{"id":"5X21-25xjBOe"}},{"cell_type":"code","source":["dataloader = torch.utils.data.DataLoader(data,\n","                                                      batch_size=32,\n","                                                      shuffle=True,\n","                                                      num_workers=8,\n","                                                      pin_memory=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQaP6ME2yaQs","executionInfo":{"status":"ok","timestamp":1696930499653,"user_tz":-120,"elapsed":224,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}},"outputId":"73b3da16-1633-4fde-d2c6-f0a4f296f3fc"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["#staticmethod\n","def forward(self, input):\n","        x = self.wavenet(input,\n","                         dilation_func=self.wavenet_dilate)\n","\n","        # reshape output\n","        #[n, c, l] = x.size()\n","        #l = self.output_length\n","        #x = x[:, :, -l:]\n","        #x = x.transpose(1, 2).contiguous()\n","        #x = x.view(n * l, c)\n","        return x"],"metadata":{"id":"dUch7NMVEpOC","executionInfo":{"status":"ok","timestamp":1696940653758,"user_tz":-120,"elapsed":228,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def wavenet(self, input, dilation_func):\n","\n","        x = self.start_conv(input)\n","        skip = 0\n","\n","        # WaveNet layers\n","        for i in range(self.blocks * self.layers):\n","\n","            #            |----------------------------------------|     *residual*\n","            #            |                                        |\n","            #            |    |-- conv -- tanh --|                |\n","            # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n","            #                 |-- conv -- sigm --|     |\n","            #                                         1x1\n","            #                                          |\n","            # ---------------------------------------> + ------------->\t*skip*\n","\n","            (dilation, init_dilation) = self.dilations[i]\n","\n","            residual = dilation_func(x, dilation, init_dilation, i)\n","\n","            # dilated convolution\n","            filter = self.filter_convs[i](residual)\n","            filter = F.tanh(filter)\n","            gate = self.gate_convs[i](residual)\n","            gate = F.sigmoid(gate)\n","            x = filter * gate\n","\n","            # parametrized skip connection\n","            s = x\n","            if x.size(2) != 1:\n","                 s = dilate(x, 1, init_dilation=dilation)\n","            s = self.skip_convs[i](s)\n","            try:\n","                skip = skip[:, :, -s.size(2):]\n","            except:\n","                skip = 0\n","            skip = s + skip\n","\n","            x = self.residual_convs[i](x)\n","            x = x + residual[:, :, (self.kernel_size - 1):]\n","\n","        x = F.relu(skip)\n","        x = F.relu(self.end_conv_1(x))\n","        x = self.end_conv_2(x)\n","\n","        return x"],"metadata":{"id":"Qc7_XydvJ3Ax","executionInfo":{"status":"ok","timestamp":1696940655680,"user_tz":-120,"elapsed":471,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def wavenet_dilate(self, input, dilation, init_dilation, i):\n","      x = dilate(input, dilation, init_dilation)\n","      return x"],"metadata":{"id":"bVR0FsV_LgDM","executionInfo":{"status":"ok","timestamp":1696940657317,"user_tz":-120,"elapsed":573,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["x=torch.Tensor(np.zeros([32, 256, 260]))\n","#x=torch.Tensor(np.random.rand(32, 256, 260))\n","x = Variable(x.type(dtype))\n","dilat=model.wavenet_dilate(x,1,1,1)\n","#print(dilation)\n","#model.wavenet(x, model.wavenet_dilate)\n","#model.forward(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"uycMR_3MDArb","executionInfo":{"status":"error","timestamp":1696940671625,"user_tz":-120,"elapsed":227,"user":{"displayName":"Francesco Sarandrea","userId":"01970008328388858960"}},"outputId":"2f3e8c0b-2de5-4d98-d709-f564541d952d"},"execution_count":14,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-9b9e6ae1dc7e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#x=torch.Tensor(np.random.rand(32, 256, 260))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdilat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavenet_dilate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(dilation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#model.wavenet(x, model.wavenet_dilate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: WaveNetModel.wavenet_dilate() missing 1 required positional argument: 'i'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"glpi4jMGEPa3"},"execution_count":null,"outputs":[]}]}