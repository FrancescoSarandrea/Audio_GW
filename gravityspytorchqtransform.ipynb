{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision\n\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-22T15:45:10.988713Z","iopub.execute_input":"2023-05-22T15:45:10.989076Z","iopub.status.idle":"2023-05-22T15:45:12.684679Z","shell.execute_reply.started":"2023-05-22T15:45:10.989042Z","shell.execute_reply":"2023-05-22T15:45:12.683701Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"try:\n    from torchsummary import summary\nexcept ModuleNotFoundError: \n    !pip install torchsummary\n    from torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:12.686661Z","iopub.execute_input":"2023-05-22T15:45:12.687270Z","iopub.status.idle":"2023-05-22T15:45:12.695379Z","shell.execute_reply.started":"2023-05-22T15:45:12.687232Z","shell.execute_reply":"2023-05-22T15:45:12.694402Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\nprint(f\"TORCH DEVICE: {device}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:12.696912Z","iopub.execute_input":"2023-05-22T15:45:12.697594Z","iopub.status.idle":"2023-05-22T15:45:12.731590Z","shell.execute_reply.started":"2023-05-22T15:45:12.697560Z","shell.execute_reply":"2023-05-22T15:45:12.730605Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"TORCH DEVICE: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dir = '../input/gravity-spy-gravitational-waves/train/train/'\ntest_dir = '../input//gravity-spy-gravitational-waves/test/test/'\nvalidation_dir = '../input//gravity-spy-gravitational-waves/validation/validation/'","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:12.733841Z","iopub.execute_input":"2023-05-22T15:45:12.734202Z","iopub.status.idle":"2023-05-22T15:45:12.747587Z","shell.execute_reply.started":"2023-05-22T15:45:12.734147Z","shell.execute_reply":"2023-05-22T15:45:12.746625Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class_names = os.listdir(train_dir)\nn_classes=len(class_names)\nn_classes","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:12.749337Z","iopub.execute_input":"2023-05-22T15:45:12.749694Z","iopub.status.idle":"2023-05-22T15:45:12.770822Z","shell.execute_reply.started":"2023-05-22T15:45:12.749640Z","shell.execute_reply":"2023-05-22T15:45:12.769822Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"code","source":"plt.figure(figsize=(10,50))\nfor fold, i in zip(class_names,range(0,len(class_names))):\n\n    plt.subplot(11,2, i+1)\n    img_read = plt.imread(train_dir+fold+'/'+os.listdir(train_dir+fold)[0])\n    plt.imshow(img_read)\n    plt.title(class_names[i])\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_shape=[64,64]\nbatch_size=128","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:15.780128Z","iopub.execute_input":"2023-05-22T15:45:15.780500Z","iopub.status.idle":"2023-05-22T15:45:15.786679Z","shell.execute_reply.started":"2023-05-22T15:45:15.780473Z","shell.execute_reply":"2023-05-22T15:45:15.785564Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"transform = torchvision.transforms.Compose([torchvision.transforms.Resize(img_shape),\n                                torchvision.transforms.ToTensor(),\n                                torchvision.transforms.Grayscale(),\n                                torchvision.transforms.Normalize((0.5), (0.5))])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:16.061256Z","iopub.execute_input":"2023-05-22T15:45:16.061532Z","iopub.status.idle":"2023-05-22T15:45:16.067141Z","shell.execute_reply.started":"2023-05-22T15:45:16.061510Z","shell.execute_reply":"2023-05-22T15:45:16.066052Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_set = torchvision.datasets.ImageFolder(train_dir, transform)\nval_set = torchvision.datasets.ImageFolder(validation_dir,transform)\n#test_set = torchvision.datasets.ImageFolder(test_dir,transform)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:18.470435Z","iopub.execute_input":"2023-05-22T15:45:18.470809Z","iopub.status.idle":"2023-05-22T15:45:22.400123Z","shell.execute_reply.started":"2023-05-22T15:45:18.470779Z","shell.execute_reply":"2023-05-22T15:45:22.399122Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n#test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:22.401922Z","iopub.execute_input":"2023-05-22T15:45:22.402299Z","iopub.status.idle":"2023-05-22T15:45:22.410473Z","shell.execute_reply.started":"2023-05-22T15:45:22.402266Z","shell.execute_reply":"2023-05-22T15:45:22.409546Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Network utility","metadata":{}},{"cell_type":"code","source":"def train(epoch,net,optimizer,scheduler, criterion,train_loader, val_loader):\n    for epoch in tqdm(range(epoch)):  \n        train_loss = 0\n        correct_train = 0\n        total_train = 0\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data\n            optimizer.zero_grad()\n            outputs = net(inputs.to(device))\n            loss = criterion(outputs, labels.to(device))\n            loss.backward()\n            optimizer.step()\n            scheduler.step(loss)\n            train_loss += loss.item()\n            _, predicted_train = torch.max(outputs, 1)\n            total_train += labels.size(0)\n            correct_train += predicted_train.eq(labels.to(device)).cpu().sum().item()\n    \n        train_accuracy = 100 * correct_train / total_train\n        val_accuracy = evaluate_accuracy(net, val_loader)\n        print('Epoch %d, train loss: %.3f, train accuracy: %.2f%%, val accuracy: %.2f%%' %\n              (epoch + 1, train_loss / len(train_loader), train_accuracy, val_accuracy))\n        \n    print('Finished Training')\n    \ndef evaluate_accuracy(model, dataloader):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in dataloader:\n            images, labels = data\n            outputs = model(images.to(device))\n            _, predicted = torch.max(outputs.data, 1)  \n            total += labels.size(0) \n            correct += (predicted == labels.to(device)).sum().item() \n    accuracy = 100 * correct / total  \n    return accuracy\n\ndef accuracy_classes(net,dataloader,classes): \n    correct_pred = {classname: 0 for classname in classes}\n    total_pred = {classname: 0 for classname in classes}\n    with torch.no_grad():\n        for data in dataloader:\n            images, labels = data\n            outputs = net(images.to(device))\n            _, predictions = torch.max(outputs, 1)\n            for label, prediction in zip(labels.to(device), predictions):\n                if label == prediction:\n                    correct_pred[classes[label]] += 1\n                total_pred[classes[label]] += 1\n\n    for classname, correct_count in correct_pred.items():\n        accuracy = 100 * float(correct_count) / total_pred[classname]\n        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:22.411942Z","iopub.execute_input":"2023-05-22T15:45:22.412694Z","iopub.status.idle":"2023-05-22T15:45:22.427824Z","shell.execute_reply.started":"2023-05-22T15:45:22.412662Z","shell.execute_reply":"2023-05-22T15:45:22.426905Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## CNN","metadata":{}},{"cell_type":"code","source":"class Flatten(nn.Module):\n    def forward(self, input):\n        batch_size = input.size(0)\n        out = input.view(batch_size,-1)\n        return out # (batch_size, *size)\n    \nclass CNN(nn.Module):\n    def __init__(self, img_shape, hidden_sizes,kernel_size,padding,dropout=False,p=0.05,act='relu',input_channel=1,n_classes=35):\n        super(CNN, self).__init__()\n\n        net=[]\n        hidden_sizes=[input_channel]+hidden_sizes\n        #print(img_shape)\n        for i in range(len(hidden_sizes)-1):\n            net.append(nn.Conv2d(hidden_sizes[i], hidden_sizes[i+1], kernel_size=kernel_size[i], padding=padding[i]))\n            img_shape=[(img_shape[0]-kernel_size[i]+2*padding[i])/1+1,(img_shape[1]-kernel_size[i]+2*padding[i])/1+1 ]\n            #print(i, img_shape)\n            net.append(nn.BatchNorm2d(hidden_sizes[i+1]))\n            if act=='relu':\n                net.append(nn.ReLU())\n            elif act=='elu':\n                net.append(nn.SiLU())\n            else:\n                net.append(nn.Tanh())\n            if dropout:\n                net.append(nn.Dropout(p=p))\n            net.append(nn.MaxPool2d(kernel_size=2, stride=2,padding=0))\n            img_shape=[(img_shape[0]-2)//2+1,(img_shape[1]-2)//2+1]\n            #print(i, img_shape)\n        net.append(Flatten())\n        #print(int(img_shape[0]*img_shape[1]*hidden_sizes[-1]))\n        net.append(nn.Linear(int(img_shape[0]*img_shape[1]*hidden_sizes[-1]), n_classes))\n        self.net=nn.ModuleList(net)\n\n        \n    def forward(self, x):\n        for l in self.net:\n            #print(x.shape)\n            x=l(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:22.430058Z","iopub.execute_input":"2023-05-22T15:45:22.430475Z","iopub.status.idle":"2023-05-22T15:45:22.445485Z","shell.execute_reply.started":"2023-05-22T15:45:22.430442Z","shell.execute_reply":"2023-05-22T15:45:22.444598Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"hidden_sizes=[128,128]\nkernel_size=[7,5]\npadding_size=[2,1]","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:22.448490Z","iopub.execute_input":"2023-05-22T15:45:22.448741Z","iopub.status.idle":"2023-05-22T15:45:22.457980Z","shell.execute_reply.started":"2023-05-22T15:45:22.448719Z","shell.execute_reply":"2023-05-22T15:45:22.457133Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"net = CNN(img_shape,hidden_sizes=hidden_sizes,kernel_size=kernel_size, padding=padding_size,n_classes=n_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.0005)\nscheduler= optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.92, patience=3, min_lr=1e-7)\nepoch=5","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:26.518975Z","iopub.execute_input":"2023-05-22T15:45:26.519362Z","iopub.status.idle":"2023-05-22T15:45:28.137579Z","shell.execute_reply.started":"2023-05-22T15:45:26.519332Z","shell.execute_reply":"2023-05-22T15:45:28.136528Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"summary(net, input_size=(1,*img_shape))","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:28.963704Z","iopub.execute_input":"2023-05-22T15:45:28.964066Z","iopub.status.idle":"2023-05-22T15:45:30.060316Z","shell.execute_reply.started":"2023-05-22T15:45:28.964036Z","shell.execute_reply":"2023-05-22T15:45:30.059125Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1          [-1, 128, 62, 62]           6,400\n       BatchNorm2d-2          [-1, 128, 62, 62]             256\n              ReLU-3          [-1, 128, 62, 62]               0\n         MaxPool2d-4          [-1, 128, 31, 31]               0\n            Conv2d-5          [-1, 128, 29, 29]         409,728\n       BatchNorm2d-6          [-1, 128, 29, 29]             256\n              ReLU-7          [-1, 128, 29, 29]               0\n         MaxPool2d-8          [-1, 128, 14, 14]               0\n           Flatten-9                [-1, 25088]               0\n           Linear-10                   [-1, 22]         551,958\n================================================================\nTotal params: 968,598\nTrainable params: 968,598\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.02\nForward/backward pass size (MB): 15.05\nParams size (MB): 3.69\nEstimated Total Size (MB): 18.76\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"train(epoch,net,optimizer,scheduler, criterion,train_loader,val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-22T15:45:33.851526Z","iopub.execute_input":"2023-05-22T15:45:33.851974Z","iopub.status.idle":"2023-05-22T16:10:13.152535Z","shell.execute_reply.started":"2023-05-22T15:45:33.851936Z","shell.execute_reply":"2023-05-22T16:10:13.151443Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee638aebcca34980ab5aacf6ba0dfb5a"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, train loss: 0.738, train accuracy: 82.05%, val accuracy: 92.00%\nEpoch 2, train loss: 0.285, train accuracy: 92.75%, val accuracy: 92.08%\nEpoch 3, train loss: 0.273, train accuracy: 93.18%, val accuracy: 92.23%\nEpoch 4, train loss: 0.272, train accuracy: 92.99%, val accuracy: 92.38%\nEpoch 5, train loss: 0.273, train accuracy: 93.13%, val accuracy: 92.15%\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_classes(net,val_loader,class_names)   ","metadata":{"execution":{"iopub.status.busy":"2023-05-22T16:10:13.154740Z","iopub.execute_input":"2023-05-22T16:10:13.155422Z","iopub.status.idle":"2023-05-22T16:11:04.847278Z","shell.execute_reply.started":"2023-05-22T16:10:13.155385Z","shell.execute_reply":"2023-05-22T16:11:04.846155Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Accuracy for class: Repeating_Blips is 95.9 %\nAccuracy for class: Power_Line is 96.2 %\nAccuracy for class: Paired_Doves is 96.9 %\nAccuracy for class: Tomte is 98.3 %\nAccuracy for class: Low_Frequency_Lines is 80.6 %\nAccuracy for class: 1400Ripples is 95.1 %\nAccuracy for class: Low_Frequency_Burst is 99.4 %\nAccuracy for class: Air_Compressor is 92.9 %\nAccuracy for class: Wandering_Line is 90.8 %\nAccuracy for class: Chirp is 90.2 %\nAccuracy for class: Violin_Mode is 87.5 %\nAccuracy for class: No_Glitch is 61.4 %\nAccuracy for class: Light_Modulation is 46.2 %\nAccuracy for class: Helix is 12.5 %\nAccuracy for class: 1080Lines is 100.0 %\nAccuracy for class: Scattered_Light is 79.3 %\nAccuracy for class: Koi_Fish is 96.7 %\nAccuracy for class: Scratchy is 98.5 %\nAccuracy for class: None_of_the_Above is 80.9 %\nAccuracy for class: Extremely_Loud is 94.9 %\nAccuracy for class: Blip  is 45.8 %\nAccuracy for class: Whistle is 81.0 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}